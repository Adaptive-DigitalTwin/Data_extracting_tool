{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Extraction\n",
    "Here from the given pdf survey file we will extract the texts and save it as text file for individual page of the survey report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def sorted_nicely( l ):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text\n",
    "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n",
    "    return sorted(l, key = alphanum_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.StringIO'>\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "import io\n",
    "import os\n",
    "\n",
    "#saving all the pages on different txt file\n",
    "#can initiate text series\n",
    "with open('SOUTH_BUO_ReportV2.pdf', 'rb') as fp:\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    print(type(retstr))\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    page_no = 1\n",
    "    for pageNumber, page in enumerate(PDFPage.get_pages(fp)):\n",
    "        if pageNumber == page_no-1:\n",
    "            interpreter.process_page(page)\n",
    "            data = retstr.getvalue()\n",
    "            \n",
    "            with open(os.path.join('text_files/', f'pdf_page_{page_no}.txt'), 'wb') as file:\n",
    "                file.write(data.encode('utf-8'))\n",
    "            data = ''\n",
    "            retstr.truncate(0)\n",
    "            retstr.seek(0)\n",
    "\n",
    "        page_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_dict = {}\n",
    "text_data_list = []\n",
    "for file in sorted_nicely(os.listdir('text_files')):\n",
    "    file_path = 'text_files/'+file\n",
    "    with open(file_path, 'r', encoding='utf-8') as fp:\n",
    "        string = fp.read()\n",
    "        text_data_dict[file] = string\n",
    "        text_data_list.append(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'XYZ\\nXYZ SOUTH BUOY ROV UWILD INSPECTION 2018\\n\\nCONFIDENTIAL DO NOT DISTRIBUTE\\n\\nREVISION RECORD / HOLD RECORD SHEET\\n\\nREVISION RECORD\\n\\nRev\\n\\nRevision Description\\n\\nIssue Date\\n\\nRevision Amendment Details\\n\\nA1\\nA2\\n\\nIssued for Approval\\nIssued for Approval\\n\\nInitial Release\\nAdded appendix for centre well top side photos\\n\\nHOLD RECORD\\n\\nHold Ref\\n\\n<HOLD01>\\n<HOLD02>\\n<HOLD03>\\n<HOLD04>\\n<HOLD05>\\n\\nDescription / Reason for Hold\\n\\nDocument Number: XYZ-YZH-OII-REP-0506, Rev A2\\n\\nPage 2 of 214\\n\\n\\x0c'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the data in the given position of the list\n",
    "(text_data_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tabular Extraction\n",
    "After getting the data from the pdf as text now we will perform tabular extraction from the given survey report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_line_in_file(file_name, string):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        #for line_index, line in enumerate(file.read().splitlines()):\n",
    "        for line_index, line in enumerate(file):\n",
    "            if line.lower().startswith(string.lower()):\n",
    "                return line_index\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_file_name_with_the_string(path, line_to_check):\n",
    "    for file in sorted_nicely(os.listdir(path)):\n",
    "        path_and_file = path + '/' + file\n",
    "        if check_for_line_in_file(path_and_file, line_to_check) != -1:\n",
    "            return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_integer_of_string(str):\n",
    "    result = \"\"\n",
    "    for i in range(len(str),0,-1):\n",
    "        if str[i-1].isdigit():\n",
    "            result = str[i-1]+result\n",
    "        else:\n",
    "            if result.isdigit():\n",
    "                break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the tables as pickle(csv) files\n",
    "import camelot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#dumping the files in the pickle\n",
    "#for file in os.listdir('survey_1_50'):\n",
    "   # d_f = pd.read_csv('survey_1_50/'+file)\n",
    "    #with open(\"tables/\" + file , \"wb\") as file1:  \n",
    "       # pickle.dump(d_f, file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "data_frames_dict = {}\n",
    "#data_frames_list = []\n",
    "for file in sorted_nicely(os.listdir('tables')):\n",
    "    with open('tables/'+ file, \"rb\") as table_file:\n",
    "        read_df =  pd.read_csv(table_file)\n",
    "        data_frames_dict[file.replace('.csv','')] = read_df\n",
    "        #data_frames_list.append(table3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table_in_report:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.page_number = -1\n",
    "        self.data_frame = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey_page_1_table_1\n",
      "survey_page_2_table_1\n",
      "survey_page_2_table_2\n",
      "survey_page_17_table_1\n",
      "survey_page_19_table_1\n"
     ]
    }
   ],
   "source": [
    "for key_idx, key in enumerate(data_frames_dict):\n",
    "    if key_idx <5:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the name of the tables from the tables index in the survey file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_with_line_given = get_file_name_with_the_string('text_files','TABLE OF TABLES')\n",
    "file_with_table_of_tables = 'text_files/'+file_with_line_given\n",
    "\n",
    "tables_from_report_index_without_df = []\n",
    "with open(file_with_table_of_tables, 'r', encoding='utf-8') as file:\n",
    "    table_count = 1  \n",
    "    for line in file:\n",
    "        line = line.lower()\n",
    "        table_number = 'table '+str(table_count)\n",
    "        if line.startswith(table_number):\n",
    "            table_name = line.replace(table_number,'')\n",
    "            table_count+=1\n",
    "            page_number_position = last_integer_of_string(line)\n",
    "            for s in ['.',page_number_position]:\n",
    "                table_name = table_name.replace(s,'')\n",
    "            #print(table_name)\n",
    "            new_table_without_df = Table_in_report(table_name)\n",
    "            new_table_without_df.page_number = int(page_number_position)-1\n",
    "            #print(new_table_without_df.page_number)\n",
    "            tables_from_report_index_without_df.append(new_table_without_df)\n",
    "            #print(tables_from_report_index_without_df[table_count-2].page_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Image Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a class page with (Text, Table, Image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Extracted_Page:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.text = ''\n",
    "        self.tables = []\n",
    "        self.Images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for table in tables_from_report_index_without_df:\n",
    "    #print(table.page_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect text, tables and Image for each extracted page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dictionary of the extracted page\n",
    "extracted_Pages = {}\n",
    "#each key gives each page\n",
    "#also can be taken from the text directory\n",
    "table_index_in_named_list = 0;\n",
    "total_table_countFrom_index = len(tables_from_report_index_without_df)\n",
    "table_name = 'None'\n",
    "for page_index, key in enumerate(text_data_dict, start=1):\n",
    "    new_name = key\n",
    "    for s in ['pdf_','.txt']:\n",
    "        new_name = new_name.replace(s,'') \n",
    "    new_page = Extracted_Page(new_name)    #forming Extracted_page for all the pages\n",
    "    new_page.text = text_data_dict[key]  #setting the text to the new page\n",
    "    \n",
    "    #find the table in the tables directory related to the page\n",
    "    #page_number_txt = key.replace('pdf_page_','')\n",
    "    #page_number = page_number_txt.replace('.txt','')\n",
    "    df_key_to_look_after = 'survey_page_'+str(page_index)+'_table_'\n",
    "    data_frame_array_in_the_page = [data_frames_dict[df_key] for df_key in data_frames_dict if (df_key.startswith(df_key_to_look_after))]\n",
    "    if len(data_frame_array_in_the_page) == 0:\n",
    "        extracted_Pages[new_name] = new_page\n",
    "        continue\n",
    "    #print('for page',page_index,'found data frames are:', len(data_frame_array_in_the_page))\n",
    "    #instead of data_frame_storing table with name, df and page_number\n",
    "    tables_array = []\n",
    "    #print(page_index)\n",
    "\n",
    "    # get the name from the tables_dictionary extracted from the file contents\n",
    "    if table_index_in_named_list <= total_table_countFrom_index-1 : \n",
    "        for d_f in data_frame_array_in_the_page: \n",
    "            table_without_df = tables_from_report_index_without_df[table_index_in_named_list]\n",
    "            new_table = Table_in_report(table_without_df.name)\n",
    "            indexed_page_in_table_sheet = table_without_df.page_number\n",
    "            \n",
    "            #print('table_page_numer:', table_without_df.page_number)\n",
    "            #print('page_numer:', page_index)\n",
    "            #print('table_number',table_index_in_named_list)\n",
    "            \n",
    "            if indexed_page_in_table_sheet == page_index:\n",
    "                table_name = new_table.name\n",
    "                #print(table_name)\n",
    "                table_index_in_named_list += 1;\n",
    "                \n",
    "            new_table.name = table_name\n",
    "            new_table.data_frame = d_f\n",
    "            new_table.page_number = page_index\n",
    "            tables_array.append(new_table)\n",
    "        new_page.tables = tables_array #setting the tables to the page\n",
    "        #print(len(new_page.tables))\n",
    "    extracted_Pages[new_name] = new_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('extracted_Pages.pickle' , 'wb') as handle:\n",
    "    pickle.dump(extracted_Pages, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extracted_Pages.pickle', 'rb') as handle:\n",
    "    extracted_Pages1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' scope of work completion \\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_Pages1['page_19'].tables[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_Pages['page_19'].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_Pages = {}\n",
    "for key in text_data_dict:\n",
    "    page = extracted_Page(key)\n",
    "    page.text = text_data_dict[key]\n",
    "    page_number_txt = key.replace('pdf_page_','')\n",
    "    page_number = page_number_txt.replace('.txt','')\n",
    "    table_key_to_look_after = 'page_'+page_number+'_table_'\n",
    "    page.tables = [tables[table_key] for table_key in tables if (table_key.startswith(table_key_to_look_after))]\n",
    "    extracted_Pages[key] = page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cleaning and re-arranging the data\n",
    "\n",
    "### i. Cleaning Text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Tabular data arranging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating transpose to remove extra column created\n",
    "import numpy as np\n",
    "def remove_unwanted_rows_colums(df):\n",
    "    df = df.dropna(axis ='columns', thresh = 1)\n",
    "    df = df.dropna(axis='index', thresh = 1 )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "marine_ass_growth_df = data_frames[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "marine_ass_growth_df = remove_unwanted_rows_colums(marine_ass_growth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_with_header_for_empty_space(df):\n",
    "    string_replacing_with = 'NaN'\n",
    "    for col in df.columns:\n",
    "        print(string_replacing_with)\n",
    "        if col[:3] == 'Unn':\n",
    "            if string_replacing_with != 'NaN':\n",
    "                df = df.rename(columns={col:string_replacing_with})\n",
    "                #print(df)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            string_replacing_with = col\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#marine_ass_growth_df = fill_with_header_for_empty_space(marine_ass_growth_df)\n",
    "#fill_with_header_for_empty_space(marine_ass_growth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marine Growth Assessment</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Location</td>\n",
       "      <td>% Cover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Max Thickness,\\nmm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average thickness,\\nmm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Morphology /\\ntype of\\nmarine growth</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05-1</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>Hydroids\\nSponges</td>\n",
       "      <td>Coral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Marine Growth Assessment Unnamed: 1 Unnamed: 2          Unnamed: 3  \\\n",
       "0                 Location    % Cover        NaN  Max Thickness,\\nmm   \n",
       "1                      NaN       Soft       Hard                Soft   \n",
       "2                     05-1         70         60                  25   \n",
       "\n",
       "  Unnamed: 4              Unnamed: 5 Unnamed: 6  \\\n",
       "0        NaN  Average thickness,\\nmm        NaN   \n",
       "1       Hard                    Soft       Hard   \n",
       "2         50                      20         35   \n",
       "\n",
       "                             Unnamed: 7 Unnamed: 8  \n",
       "0  Morphology /\\ntype of\\nmarine growth        NaN  \n",
       "1                                  Soft       Hard  \n",
       "2                     Hydroids\\nSponges      Coral  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marine_ass_growth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_top_header_for_NAN_spaces(df,n_row):\n",
    "    header_replacing_with = 'NaN'\n",
    "    col_idx = -1\n",
    "    row_length = len(df.index)\n",
    "    horizontal_replacing_strings = ['NaN']*n_row\n",
    "    for col in df.columns:\n",
    "        col_idx +=1 \n",
    "        #replacement of Unnamed for column name\n",
    "        if col[:3] == 'Unn':\n",
    "            if header_replacing_with != 'NaN':\n",
    "                df = df.rename(columns={col:header_replacing_with})\n",
    "                #print(df)\n",
    "        else:\n",
    "            header_replacing_with = col\n",
    "        for j in range(n_row):\n",
    "            cell_data = df.iloc[j,col_idx]\n",
    "            #print(cell_data)\n",
    "            if pd.isnull(df.iloc[j,col_idx]):\n",
    "                if horizontal_replacing_strings[j] != 'NaN':\n",
    "                    df.iat[j, col_idx] = horizontal_replacing_strings[j]\n",
    "            else:\n",
    "                horizontal_replacing_strings[j] = cell_data \n",
    "                #print(horizontal_replacing_strings)\n",
    "        #replacing NAN with vertical replacement\n",
    "        #if (col_idx < 3)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marine Growth Assessment</th>\n",
       "      <th>Marine Growth Assessment</th>\n",
       "      <th>Marine Growth Assessment</th>\n",
       "      <th>Marine Growth Assessment</th>\n",
       "      <th>Marine Growth Assessment</th>\n",
       "      <th>Marine Growth Assessment</th>\n",
       "      <th>Marine Growth Assessment</th>\n",
       "      <th>Marine Growth Assessment</th>\n",
       "      <th>Marine Growth Assessment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Location</td>\n",
       "      <td>% Cover</td>\n",
       "      <td>% Cover</td>\n",
       "      <td>Max Thickness,\\nmm</td>\n",
       "      <td>Max Thickness,\\nmm</td>\n",
       "      <td>Average thickness,\\nmm</td>\n",
       "      <td>Average thickness,\\nmm</td>\n",
       "      <td>Morphology /\\ntype of\\nmarine growth</td>\n",
       "      <td>Morphology /\\ntype of\\nmarine growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>05-1</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>Hydroids\\nSponges</td>\n",
       "      <td>Coral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Marine Growth Assessment Marine Growth Assessment Marine Growth Assessment  \\\n",
       "0                 Location                  % Cover                  % Cover   \n",
       "1                      NaN                     Soft                     Hard   \n",
       "2                     05-1                       70                       60   \n",
       "\n",
       "  Marine Growth Assessment Marine Growth Assessment Marine Growth Assessment  \\\n",
       "0       Max Thickness,\\nmm       Max Thickness,\\nmm   Average thickness,\\nmm   \n",
       "1                     Soft                     Hard                     Soft   \n",
       "2                       25                       50                       20   \n",
       "\n",
       "  Marine Growth Assessment              Marine Growth Assessment  \\\n",
       "0   Average thickness,\\nmm  Morphology /\\ntype of\\nmarine growth   \n",
       "1                     Hard                                  Soft   \n",
       "2                       35                     Hydroids\\nSponges   \n",
       "\n",
       "               Marine Growth Assessment  \n",
       "0  Morphology /\\ntype of\\nmarine growth  \n",
       "1                                  Hard  \n",
       "2                                 Coral  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marine Growth Assessment</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Location</td>\n",
       "      <td>Madhu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Max Thickness,\\nmm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average thickness,\\nmm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Morphology /\\ntype of\\nmarine growth</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "      <td>Soft</td>\n",
       "      <td>Hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>05-1</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>Hydroids\\nSponges</td>\n",
       "      <td>Coral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Marine Growth Assessment Unnamed: 1 Unnamed: 2          Unnamed: 3  \\\n",
       "0                 Location      Madhu        NaN  Max Thickness,\\nmm   \n",
       "1                      NaN       Soft       Hard                Soft   \n",
       "2                     05-1         70         60                  25   \n",
       "\n",
       "  Unnamed: 4              Unnamed: 5 Unnamed: 6  \\\n",
       "0        NaN  Average thickness,\\nmm        NaN   \n",
       "1       Hard                    Soft       Hard   \n",
       "2         50                      20         35   \n",
       "\n",
       "                             Unnamed: 7 Unnamed: 8  \n",
       "0  Morphology /\\ntype of\\nmarine growth        NaN  \n",
       "1                                  Soft       Hard  \n",
       "2                     Hydroids\\nSponges      Coral  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df100 =  pickle.load(open('tables/tables101.csv', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mooring\\nLine</th>\n",
       "      <th>Anomaly</th>\n",
       "      <th>Type</th>\n",
       "      <th>Detail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>YZH/2018OI3/02</td>\n",
       "      <td>AW</td>\n",
       "      <td>Connector tube anode is 50% depleted.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>YZH/2018OI3/03</td>\n",
       "      <td>AW</td>\n",
       "      <td>Connector tube anode is 100% depleted.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CP</td>\n",
       "      <td>A low CP reading obtained on the connector tub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>YZH/2018OI3/06</td>\n",
       "      <td>AW</td>\n",
       "      <td>Connector tube anode is 100% depleted.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CP</td>\n",
       "      <td>A low CP reading obtained on the connector tub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PD</td>\n",
       "      <td>A continuity strap on the connector body is se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BM</td>\n",
       "      <td>The severed cable is fretting against the plat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>YZH/2018OI3/05</td>\n",
       "      <td>AW</td>\n",
       "      <td>Connector tube anode is 100% depleted.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CP</td>\n",
       "      <td>A low CP reading obtained on the connector tub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DB</td>\n",
       "      <td>Fishing net is attached to the lower anode stu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mooring\\nLine         Anomaly Type  \\\n",
       "0             1.0            None  NaN   \n",
       "1             2.0            None  NaN   \n",
       "2             3.0            None  NaN   \n",
       "3             4.0  YZH/2018OI3/02   AW   \n",
       "4             5.0  YZH/2018OI3/03   AW   \n",
       "5             NaN             NaN   CP   \n",
       "6             6.0  YZH/2018OI3/06   AW   \n",
       "7             NaN             NaN   CP   \n",
       "8             NaN             NaN   PD   \n",
       "9             NaN             NaN   BM   \n",
       "10            7.0  YZH/2018OI3/05   AW   \n",
       "11            NaN             NaN   CP   \n",
       "12            NaN             NaN   DB   \n",
       "\n",
       "                                               Detail  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3               Connector tube anode is 50% depleted.  \n",
       "4              Connector tube anode is 100% depleted.  \n",
       "5   A low CP reading obtained on the connector tub...  \n",
       "6              Connector tube anode is 100% depleted.  \n",
       "7   A low CP reading obtained on the connector tub...  \n",
       "8   A continuity strap on the connector body is se...  \n",
       "9   The severed cable is fretting against the plat...  \n",
       "10             Connector tube anode is 100% depleted.  \n",
       "11  A low CP reading obtained on the connector tub...  \n",
       "12  Fishing net is attached to the lower anode stu...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_side_header_for_NAN_spaces(df, n_col):\n",
    "    horizontal_replacing_strings = ['NaN', 'NaN', 'NaN']\n",
    "    for col in df.columns:\n",
    "        col_idx +=1 \n",
    "        #replacement of Unnamed for column name\n",
    "        if col[:3] == 'Unn':\n",
    "            if header_replacing_with != 'NaN':\n",
    "                df = df.rename(columns={col:header_replacing_with})\n",
    "                #print(df)\n",
    "        else:\n",
    "            header_replacing_with = col\n",
    "        #row_idx = 0\n",
    "        for j in range(3):\n",
    "            cell_data = df.iloc[j,col_idx]\n",
    "            #print(cell_data)\n",
    "            if pd.isnull(df.iloc[j,col_idx]):\n",
    "                if horizontal_replacing_strings[j] != 'NaN':\n",
    "                    df.iat[j, col_idx] = horizontal_replacing_strings[j]\n",
    "            else:\n",
    "                horizontal_replacing_strings[j] = cell_data \n",
    "                #print(horizontal_replacing_strings)\n",
    "        #replacing NAN with vertical replacement\n",
    "        #if (col_idx < 3)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_replacing_strings = ['NaN']*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NaN', 'NaN', 'NaN']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horizontal_replacing_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
